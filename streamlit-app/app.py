# -*- coding: utf-8 -*-
"""
ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦ TOPICSå‡ºã—ã‚¢ãƒ—ãƒª
Streamlitç‰ˆ v1.0
"""

import streamlit as st
import pandas as pd
from scraper import OriconScraper
from analyzer import TopicsAnalyzer

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚ªãƒªã‚³ãƒ³ TOPICSå‡ºã—",
    page_icon="ğŸ“°",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ“° ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦ TOPICSå‡ºã—")
st.markdown("ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®è¦‹å‡ºã—ãƒˆãƒ”ãƒƒã‚¯ã‚¹å€™è£œã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°é¸æŠ
# æ³¨æ„: URLã¯ rank-xxx ã¾ãŸã¯ rank_xxx ã®å½¢å¼ãŒã‚ã‚‹
ranking_options = {
    "æºå¸¯ã‚­ãƒ£ãƒªã‚¢": "mobile-carrier",
    "æ ¼å®‰SIM": "mvno",
    "FX": "_fx",  # rank_fx
    "éŠ€è¡Œã‚«ãƒ¼ãƒ‰ãƒ­ãƒ¼ãƒ³": "card-loan",
    "ãƒãƒ³ãƒãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ãƒ­ãƒ¼ãƒ³": "card-loan/nonbank",
    "ãƒãƒƒãƒˆè¨¼åˆ¸": "_certificate",  # rank_certificate
    "iDeCoè¨¼åˆ¸ä¼šç¤¾": "ideco",
    "è‡ªå‹•è»Šä¿é™º": "car-insurance",
    "ç”Ÿå‘½ä¿é™º": "life-insurance",
    "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰": "creditcard",
    "è»¢è·ã‚µã‚¤ãƒˆ": "recruit",
    "è‹±ä¼šè©±ã‚¹ã‚¯ãƒ¼ãƒ«": "english-school",
    "ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›": "custom"
}

selected_ranking = st.sidebar.selectbox(
    "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’é¸æŠ",
    list(ranking_options.keys())
)

# ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›ã®å ´åˆ
if selected_ranking == "ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›":
    ranking_slug = st.sidebar.text_input(
        "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®URLå",
        placeholder="ä¾‹: mobile-carrier"
    )
    ranking_name = st.sidebar.text_input(
        "ãƒ©ãƒ³ã‚­ãƒ³ã‚°åï¼ˆè¡¨ç¤ºç”¨ï¼‰",
        placeholder="ä¾‹: æºå¸¯ã‚­ãƒ£ãƒªã‚¢"
    )
else:
    ranking_slug = ranking_options[selected_ranking]
    ranking_name = selected_ranking

# å¹´åº¦é¸æŠ
current_year = 2024
start_year = 2006  # ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦èª¿æŸ»é–‹å§‹å¹´

year_option = st.sidebar.radio(
    "å–å¾—ã™ã‚‹å¹´åº¦ç¯„å›²",
    ["ç›´è¿‘3å¹´", "ç›´è¿‘5å¹´", "å…¨å¹´åº¦ï¼ˆ2006å¹´ã€œï¼‰", "ã‚«ã‚¹ã‚¿ãƒ ç¯„å›²"]
)

if year_option == "ç›´è¿‘3å¹´":
    year_range = (current_year - 2, current_year)
elif year_option == "ç›´è¿‘5å¹´":
    year_range = (current_year - 4, current_year)
elif year_option == "å…¨å¹´åº¦ï¼ˆ2006å¹´ã€œï¼‰":
    year_range = (start_year, current_year)
else:  # ã‚«ã‚¹ã‚¿ãƒ ç¯„å›²
    year_range = st.sidebar.slider(
        "å¹´åº¦ç¯„å›²ã‚’é¸æŠ",
        min_value=start_year,
        max_value=current_year,
        value=(current_year - 4, current_year)
    )

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸš€ TOPICSå‡ºã—å®Ÿè¡Œ", type="primary"):

    if not ranking_slug:
        st.error("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®URLåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢
        debug_expander = st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°", expanded=True)
        debug_logs = []

        def log(message):
            debug_logs.append(message)
            with debug_expander:
                st.text("\n".join(debug_logs))

        try:
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–
            log(f"[INFO] ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–: {ranking_slug} ({ranking_name})")
            scraper = OriconScraper(ranking_slug, ranking_name)
            subpath_info = f" + subpath: {scraper.subpath}" if scraper.subpath else ""
            log(f"[INFO] URL prefix: {scraper.url_prefix}{subpath_info}")

            # Step 1: ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—
            status_text.text(f"ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ä¸­... ({year_range[0]}å¹´ã€œ{year_range[1]}å¹´)")
            progress_bar.progress(10)

            overall_data = scraper.get_overall_rankings(year_range)
            log(f"[OK] ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(overall_data)}å¹´åˆ†å–å¾—")
            for year, data in overall_data.items():
                log(f"  - {year}å¹´: {len(data)}ç¤¾")
            progress_bar.progress(30)

            # Step 2: è©•ä¾¡é …ç›®åˆ¥å–å¾—ï¼ˆçµŒå¹´ï¼‰
            status_text.text(f"ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... ({year_range[0]}å¹´ã€œ{year_range[1]}å¹´)")
            item_data = scraper.get_evaluation_items(year_range)
            log(f"[OK] è©•ä¾¡é …ç›®åˆ¥: {len(item_data)}é …ç›®")
            for item_name in item_data.keys():
                log(f"  - {item_name}")
            progress_bar.progress(50)

            # Step 3: éƒ¨é–€åˆ¥å–å¾—ï¼ˆçµŒå¹´ï¼‰
            status_text.text(f"ğŸ·ï¸ éƒ¨é–€åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... ({year_range[0]}å¹´ã€œ{year_range[1]}å¹´)")
            dept_data = scraper.get_departments(year_range)
            log(f"[OK] éƒ¨é–€åˆ¥: {len(dept_data)}éƒ¨é–€")
            for dept_name in dept_data.keys():
                log(f"  - {dept_name}")
            progress_bar.progress(70)

            # Step 4: åˆ†æå®Ÿè¡Œ
            status_text.text("ğŸ” TOPICSåˆ†æä¸­...")
            analyzer = TopicsAnalyzer(overall_data, item_data, ranking_name)
            topics = analyzer.analyze()
            progress_bar.progress(90)

            # å®Œäº†
            status_text.text("âœ… å®Œäº†!")
            progress_bar.progress(100)

            # çµæœè¡¨ç¤º
            st.success(f"âœ… {ranking_name}ã®TOPICSå‡ºã—ãŒå®Œäº†ã—ã¾ã—ãŸ")

            # ã‚¿ãƒ–ã§çµæœè¡¨ç¤º
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                "â­ æ¨å¥¨TOPICS",
                "ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´ï¼‰",
                "ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥",
                "ğŸ·ï¸ éƒ¨é–€åˆ¥",
                "ğŸ¯ è¦‹å‡ºã—æ¡ˆ",
                "ğŸ“ å‚è€ƒè³‡æ–™"
            ])

            with tab1:
                st.header("â­ æ¨å¥¨TOPICS")
                for i, topic in enumerate(topics["recommended"], 1):
                    importance = topic.get("importance", "é‡è¦")
                    st.markdown(f"### {i}. [{importance}] {topic['title']}")
                    st.markdown(f"- **æ ¹æ‹ **: {topic['evidence']}")
                    st.markdown(f"- **ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: {'â˜…' * topic.get('impact', 3)}")
                    st.divider()

                if topics.get("other"):
                    st.subheader("ğŸ“Š ãã®ä»–ã®TOPICSå€™è£œ")
                    for topic in topics["other"]:
                        st.markdown(f"- {topic}")

            with tab2:
                st.header("ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´è©³ç´°ï¼‰")
                if overall_data:
                    # å¹´åº¦ã”ã¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    for year in sorted(overall_data.keys(), reverse=True):
                        with st.expander(f"ğŸ“… {year}å¹´", expanded=(year == max(overall_data.keys()))):
                            df = pd.DataFrame(overall_data[year])
                            st.dataframe(df, use_container_width=True)

                    # çµŒå¹´æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆ1ä½ã€œ4ä½ã®æ¨ç§»ï¼‰
                    st.subheader("ğŸ“ˆ çµŒå¹´æ¯”è¼ƒï¼ˆå…¨ç¤¾å¾—ç‚¹æ¨ç§»ï¼‰")

                    # ä¼æ¥­ã”ã¨ã®çµŒå¹´ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
                    companies = set()
                    for year_data in overall_data.values():
                        for item in year_data:
                            companies.add(item.get("company", ""))

                    comparison_data = []
                    for company in sorted(companies):
                        row = {"ä¼æ¥­å": company}
                        for year in sorted(overall_data.keys()):
                            score = "-"
                            rank = "-"
                            for item in overall_data[year]:
                                if item.get("company") == company:
                                    score = item.get("score", "-")
                                    rank = item.get("rank", "-")
                                    break
                            row[f"{year}å¹´å¾—ç‚¹"] = score
                            row[f"{year}å¹´é †ä½"] = rank
                        comparison_data.append(row)

                    if comparison_data:
                        st.dataframe(pd.DataFrame(comparison_data), use_container_width=True)

            with tab3:
                st.header("ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´ï¼‰")
                if item_data:
                    for item_name, year_data in item_data.items():
                        with st.expander(f"ğŸ“Œ {item_name}", expanded=False):
                            if isinstance(year_data, dict):
                                # çµŒå¹´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
                                for year in sorted(year_data.keys(), reverse=True):
                                    st.markdown(f"**{year}å¹´**")
                                    df = pd.DataFrame(year_data[year])
                                    st.dataframe(df, use_container_width=True)

                                # çµŒå¹´æ¯”è¼ƒï¼ˆ1ä½ã®æ¨ç§»ï¼‰
                                if len(year_data) > 1:
                                    st.markdown("**ğŸ“ˆ 1ä½ã®æ¨ç§»**")
                                    history = []
                                    for year in sorted(year_data.keys(), reverse=True):
                                        if year_data[year]:
                                            top = year_data[year][0]
                                            history.append({
                                                "å¹´åº¦": year,
                                                "1ä½": top.get("company", "-"),
                                                "å¾—ç‚¹": top.get("score", "-")
                                            })
                                    if history:
                                        st.dataframe(pd.DataFrame(history), use_container_width=True)
                            else:
                                # æ—§å½¢å¼ï¼ˆå˜å¹´ãƒ‡ãƒ¼ã‚¿ï¼‰ã®å ´åˆ
                                df = pd.DataFrame(year_data)
                                st.dataframe(df, use_container_width=True)
                else:
                    st.info("è©•ä¾¡é …ç›®åˆ¥ãƒ‡ãƒ¼ã‚¿ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            with tab4:
                st.header("ğŸ·ï¸ éƒ¨é–€åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´ï¼‰")
                if dept_data:
                    for dept_name, year_data in dept_data.items():
                        with st.expander(f"ğŸ“Œ {dept_name}", expanded=False):
                            if isinstance(year_data, dict):
                                for year in sorted(year_data.keys(), reverse=True):
                                    st.markdown(f"**{year}å¹´**")
                                    df = pd.DataFrame(year_data[year])
                                    st.dataframe(df, use_container_width=True)

                                # çµŒå¹´æ¯”è¼ƒï¼ˆ1ä½ã®æ¨ç§»ï¼‰
                                if len(year_data) > 1:
                                    st.markdown("**ğŸ“ˆ 1ä½ã®æ¨ç§»**")
                                    history = []
                                    for year in sorted(year_data.keys(), reverse=True):
                                        if year_data[year]:
                                            top = year_data[year][0]
                                            history.append({
                                                "å¹´åº¦": year,
                                                "1ä½": top.get("company", "-"),
                                                "å¾—ç‚¹": top.get("score", "-")
                                            })
                                    if history:
                                        st.dataframe(pd.DataFrame(history), use_container_width=True)
                else:
                    st.info("éƒ¨é–€åˆ¥ãƒ‡ãƒ¼ã‚¿ã¯å­˜åœ¨ã—ãªã„ã‹å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            with tab5:
                st.header("ğŸ¯ è¦‹å‡ºã—æ¡ˆ")
                for i, headline in enumerate(topics.get("headlines", []), 1):
                    st.markdown(f"**ãƒ‘ã‚¿ãƒ¼ãƒ³{i}**: {headline}")

                # ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆ
                st.subheader("ğŸ“‹ ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆ")
                copy_text = "\n".join([
                    "ã€æ¨å¥¨TOPICSã€‘",
                    *[f"{i}. {t['title']}" for i, t in enumerate(topics["recommended"], 1)],
                    "",
                    "ã€è¦‹å‡ºã—æ¡ˆã€‘",
                    *[f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i}: {h}" for i, h in enumerate(topics.get("headlines", []), 1)]
                ])
                st.text_area("ã‚³ãƒ”ãƒ¼ç”¨", copy_text, height=300, label_visibility="collapsed")

            with tab6:
                st.header("ğŸ“ å‚è€ƒè³‡æ–™ï¼ˆä½¿ç”¨ã—ãŸURLï¼‰")

                # ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°URL
                st.subheader("ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                overall_urls = scraper.used_urls.get("overall", [])
                if overall_urls:
                    for item in overall_urls:
                        status = "âœ…" if item["status"] == "success" else "âŒ"
                        st.markdown(f"{status} **{item['year']}å¹´**: [{item['url']}]({item['url']})")

                # è©•ä¾¡é …ç›®åˆ¥URL
                st.subheader("è©•ä¾¡é …ç›®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                item_urls = scraper.used_urls.get("items", [])
                if item_urls:
                    with st.expander("è©•ä¾¡é …ç›®åˆ¥URLä¸€è¦§", expanded=False):
                        for item in item_urls:
                            status = "âœ…" if item["status"] == "success" else "âŒ"
                            st.markdown(f"{status} **{item['name']}**: [{item['url']}]({item['url']})")

                # éƒ¨é–€åˆ¥URL
                st.subheader("éƒ¨é–€åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                dept_urls = scraper.used_urls.get("departments", [])
                if dept_urls:
                    with st.expander("éƒ¨é–€åˆ¥URLä¸€è¦§", expanded=False):
                        for item in dept_urls:
                            status = "âœ…" if item["status"] == "success" else "âŒ"
                            st.markdown(f"{status} **{item['name']}**: [{item['url']}]({item['url']})")
                else:
                    st.info("éƒ¨é–€åˆ¥ãƒ‡ãƒ¼ã‚¿ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸ")

                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
                st.divider()
                st.markdown("**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: [ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°](https://life.oricon.co.jp/)")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.exception(e)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.sidebar.divider()
st.sidebar.markdown("---")
st.sidebar.markdown("ğŸ“Œ **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: life.oricon.co.jp")
st.sidebar.markdown("ğŸ”§ **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0")
