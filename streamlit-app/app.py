# -*- coding: utf-8 -*-
"""
ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦Â®èª¿æŸ» TOPICSã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 
Streamlitç‰ˆ v3.5 - å¹´åº¦åˆ—æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯æ”¹å–„ç‰ˆ
- å¹´åº¦åˆ—ã®èª¤æ¤œå‡ºã‚’é˜²æ­¢ï¼ˆå›ç­”è€…æ•°ï¼ˆæœ€æ–°å¹´ï¼‰ç­‰ã‚’é™¤å¤–ï¼‰
- å¹´åº¦å€¤ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ2000-2030ç¯„å›²å¤–ã¯æŒ‡å®šå¹´åº¦ã‚’ä½¿ç”¨ï¼‰
- ã‚ªãƒªã‚³ãƒ³å†…éƒ¨Excelãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œè‡ªå‹•æ¤œå‡ºï¼‰
- å¹´åº¦åˆ—ãŒãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¹´åº¦ã‚’æ¨æ¸¬
- åˆ—åã®æŸ”è»Ÿãªæ¤œå‡ºï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ä¼æ¥­åã€ã‚¹ã‚³ã‚¢ç­‰ï¼‰
"""

import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
from scraper import OriconScraper
from analyzer import TopicsAnalyzer, HistoricalAnalyzer


def create_excel_export(ranking_name, overall_data, item_data, dept_data, historical_data, used_urls=None):
    """å–å¾—ãƒ‡ãƒ¼ã‚¿ã‚’Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    output = BytesIO()

    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        workbook = writer.book

        # === ã‚·ãƒ¼ãƒˆ1: ã‚µãƒãƒªãƒ¼ ===
        summary_data = []
        records = historical_data.get("historical_records", {})
        summary = records.get("summary", {})

        if summary.get("max_consecutive"):
            mc = summary["max_consecutive"]
            summary_data.append(["æœ€é•·é€£ç¶š1ä½", mc["company"], f"{mc['years']}å¹´é€£ç¶š", f"{mc['start_year']}ã€œ{mc['end_year']}"])
        if summary.get("all_time_high"):
            ath = summary["all_time_high"]
            summary_data.append(["éå»æœ€é«˜å¾—ç‚¹", ath["company"], f"{ath['score']}ç‚¹", f"{ath['year']}å¹´"])
        if summary.get("most_wins"):
            mw = summary["most_wins"]
            summary_data.append(["æœ€å¤š1ä½ç²å¾—", mw["company"], f"{mw['wins']}å›", f"{mw['total_years']}å¹´ä¸­"])

        if summary_data:
            df_summary = pd.DataFrame(summary_data, columns=["è¨˜éŒ²", "ä¼æ¥­å", "æ•°å€¤", "è©³ç´°"])
            df_summary.to_excel(writer, sheet_name="ã‚µãƒãƒªãƒ¼", index=False)

        # === ã‚·ãƒ¼ãƒˆ2: ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå…¨å¹´åº¦ï¼‰ ===
        all_overall = []
        for year in sorted(overall_data.keys(), reverse=True):
            for item in overall_data[year]:
                all_overall.append({
                    "å¹´åº¦": year,
                    "é †ä½": item.get("rank"),
                    "ä¼æ¥­å": item.get("company"),
                    "å¾—ç‚¹": item.get("score")
                })
        if all_overall:
            pd.DataFrame(all_overall).to_excel(writer, sheet_name="ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°", index=False)

        # === ã‚·ãƒ¼ãƒˆ3: çµŒå¹´æ¯”è¼ƒï¼ˆãƒ”ãƒœãƒƒãƒˆï¼‰ ===
        companies = set()
        for year_data in overall_data.values():
            for item in year_data:
                companies.add(item.get("company", ""))

        pivot_data = []
        for company in sorted(companies):
            if not company:
                continue
            row = {"ä¼æ¥­å": company}
            for year in sorted(overall_data.keys()):
                score = None
                rank = None
                for item in overall_data.get(year, []):
                    if item.get("company") == company:
                        score = item.get("score")
                        rank = item.get("rank")
                        break
                row[f"{year}å¹´_å¾—ç‚¹"] = score if score else ""
                row[f"{year}å¹´_é †ä½"] = rank if rank else ""
            pivot_data.append(row)
        if pivot_data:
            pd.DataFrame(pivot_data).to_excel(writer, sheet_name="çµŒå¹´æ¯”è¼ƒ", index=False)

        # === ã‚·ãƒ¼ãƒˆ4: é€£ç¶š1ä½è¨˜éŒ² ===
        consecutive = records.get("consecutive_wins", [])
        if consecutive:
            df_cons = pd.DataFrame([
                {
                    "ä¼æ¥­å": r["company"],
                    "é€£ç¶šå¹´æ•°": r["years"],
                    "é–‹å§‹å¹´": r["start_year"],
                    "çµ‚äº†å¹´": r["end_year"],
                    "ç¶™ç¶šä¸­": "â—‹" if r.get("is_current") else ""
                }
                for r in consecutive
            ])
            df_cons.to_excel(writer, sheet_name="é€£ç¶š1ä½è¨˜éŒ²", index=False)

        # === ã‚·ãƒ¼ãƒˆ5: 1ä½ç²å¾—å›æ•° ===
        most_wins = records.get("most_wins", [])
        if most_wins:
            df_wins = pd.DataFrame([
                {
                    "ä¼æ¥­å": r["company"],
                    "1ä½å›æ•°": r["wins"],
                    "ç·å¹´æ•°": r["total_years"],
                    "ç²å¾—ç‡": f"{r['wins']/r['total_years']*100:.1f}%",
                    "ç²å¾—å¹´": ", ".join(map(str, r["years"]))
                }
                for r in most_wins
            ])
            df_wins.to_excel(writer, sheet_name="1ä½ç²å¾—å›æ•°", index=False)

        # === ã‚·ãƒ¼ãƒˆ6: éå»æœ€é«˜å¾—ç‚¹ ===
        highest = records.get("highest_scores", [])
        if highest:
            df_high = pd.DataFrame([
                {
                    "é †ä½": i,
                    "ä¼æ¥­å": r["company"],
                    "å¾—ç‚¹": r["score"],
                    "å¹´åº¦": r["year"],
                    "ãã®å¹´ã®é †ä½": r["rank"]
                }
                for i, r in enumerate(highest[:20], 1)
            ])
            df_high.to_excel(writer, sheet_name="éå»æœ€é«˜å¾—ç‚¹", index=False)

        # === ã‚·ãƒ¼ãƒˆ7ã€œ: è©•ä¾¡é …ç›®åˆ¥ ===
        for item_name, year_data in item_data.items():
            if isinstance(year_data, dict):
                item_rows = []
                for year in sorted(year_data.keys(), reverse=True):
                    for item in year_data.get(year, []):
                        item_rows.append({
                            "å¹´åº¦": year,
                            "é †ä½": item.get("rank"),
                            "ä¼æ¥­å": item.get("company"),
                            "å¾—ç‚¹": item.get("score")
                        })
                if item_rows:
                    sheet_name = f"é …ç›®_{item_name[:20]}"
                    sheet_name = sheet_name.replace("/", "_").replace("\\", "_")[:31]
                    pd.DataFrame(item_rows).to_excel(writer, sheet_name=sheet_name, index=False)

        # === éƒ¨é–€åˆ¥ ===
        for dept_name, year_data in dept_data.items():
            if isinstance(year_data, dict):
                dept_rows = []
                for year in sorted(year_data.keys(), reverse=True):
                    for item in year_data.get(year, []):
                        dept_rows.append({
                            "å¹´åº¦": year,
                            "é †ä½": item.get("rank"),
                            "ä¼æ¥­å": item.get("company"),
                            "å¾—ç‚¹": item.get("score")
                        })
                if dept_rows:
                    sheet_name = f"éƒ¨é–€_{dept_name[:20]}"
                    sheet_name = sheet_name.replace("/", "_").replace("\\", "_")[:31]
                    pd.DataFrame(dept_rows).to_excel(writer, sheet_name=sheet_name, index=False)

        # === å‚è€ƒè³‡æ–™ï¼ˆURLï¼‰ã‚·ãƒ¼ãƒˆ ===
        if used_urls:
            url_rows = []
            for item in used_urls.get("overall", []):
                url_rows.append({
                    "ã‚«ãƒ†ã‚´ãƒª": "ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°",
                    "å¹´åº¦/é …ç›®": item.get("year", ""),
                    "URL": item.get("url", ""),
                    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æˆåŠŸ" if item.get("status") == "success" else "å¤±æ•—"
                })
            for item in used_urls.get("items", []):
                url_rows.append({
                    "ã‚«ãƒ†ã‚´ãƒª": "è©•ä¾¡é …ç›®åˆ¥",
                    "å¹´åº¦/é …ç›®": item.get("name", ""),
                    "URL": item.get("url", ""),
                    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æˆåŠŸ" if item.get("status") == "success" else "å¤±æ•—"
                })
            for item in used_urls.get("departments", []):
                url_rows.append({
                    "ã‚«ãƒ†ã‚´ãƒª": "éƒ¨é–€åˆ¥",
                    "å¹´åº¦/é …ç›®": item.get("name", ""),
                    "URL": item.get("url", ""),
                    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "æˆåŠŸ" if item.get("status") == "success" else "å¤±æ•—"
                })
            if url_rows:
                pd.DataFrame(url_rows).to_excel(writer, sheet_name="å‚è€ƒè³‡æ–™URL", index=False)

    output.seek(0)
    return output.getvalue()


def parse_uploaded_excel(uploaded_file, specified_year=None):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

    å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
    1. æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¹´åº¦åˆ—ã‚ã‚Šï¼‰
    2. ã‚ªãƒªã‚³ãƒ³å†…éƒ¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¹´åº¦ãªã—ã€ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒ3è¡Œç›®ä»¥é™ï¼‰
    3. è©•ä¾¡é …ç›®ã‚·ãƒ¼ãƒˆï¼ˆ1åˆ—ç›®ã«è©•ä¾¡é …ç›®åï¼‰
    4. éƒ¨é–€åˆ¥ã‚·ãƒ¼ãƒˆï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ä¸Šã«ã‚«ãƒ†ã‚´ãƒªåï¼‰

    Args:
        uploaded_file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        specified_year: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸå¹´åº¦ï¼ˆNoneã®å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬ï¼‰
    """
    try:
        xl = pd.ExcelFile(uploaded_file)
        sheet_names = xl.sheet_names

        overall_data = {}
        item_data = {}
        dept_data = {}

        # å¹´åº¦ã‚’æ±ºå®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®š > ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬ > ç¾åœ¨å¹´ï¼‰
        if specified_year:
            inferred_year = specified_year
        else:
            filename = uploaded_file.name if hasattr(uploaded_file, 'name') else ""
            import re
            year_match = re.search(r'20\d{2}', filename)
            if year_match:
                inferred_year = int(year_match.group())
            else:
                inferred_year = datetime.now().year

        for sheet_name in sheet_names:
            # ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‚·ãƒ¼ãƒˆ
            skip_sheets = ['ç¶™ç¶šåˆ©ç”¨æ„å‘', 'æ¨å¥¨æ„å‘', 'ä½œæ¥­ç”¨']
            if any(skip in sheet_name for skip in skip_sheets):
                continue

            # ã¾ãšãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã§èª­ã¿è¾¼ã‚“ã§ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡º
            df_raw = pd.read_excel(xl, sheet_name=sheet_name, header=None)

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡ºï¼ˆ"é †ä½"ã¨"ID"ã‚’å«ã‚€è¡Œï¼‰
            header_row = None
            category_name = None  # éƒ¨é–€åˆ¥ã‚·ãƒ¼ãƒˆã®ã‚«ãƒ†ã‚´ãƒªå
            for idx, row in df_raw.iterrows():
                row_str = ' '.join([str(v) for v in row.values if pd.notna(v)])
                if 'é †ä½' in row_str and 'ID' in row_str and ('ä¼æ¥­' in row_str or 'ãƒ©ãƒ³ã‚­ãƒ³ã‚°' in row_str):
                    header_row = idx
                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ä¸Šã«ã‚«ãƒ†ã‚´ãƒªåãŒã‚ã‚‹å ´åˆï¼ˆéƒ¨é–€åˆ¥ã‚·ãƒ¼ãƒˆï¼‰
                    # æ§‹é€ : Row0=FX, Row1=ã‚·ãƒ¼ãƒˆå, Row2=ã‚«ãƒ†ã‚´ãƒªå, Row3=nï¼, Row4=ãƒ˜ãƒƒãƒ€ãƒ¼
                    if idx >= 2:
                        # Row2ã‚’å„ªå…ˆçš„ã«ç¢ºèªï¼ˆé€šå¸¸ã‚«ãƒ†ã‚´ãƒªåãŒã‚ã‚‹å ´æ‰€ï¼‰
                        for cat_idx in [2, idx - 2, idx - 1]:
                            if cat_idx < 0 or cat_idx >= idx:
                                continue
                            cat_row = df_raw.iloc[cat_idx]
                            cat_val = cat_row.iloc[0] if pd.notna(cat_row.iloc[0]) else None
                            if cat_val:
                                cat_str = str(cat_val)
                                # é™¤å¤–æ¡ä»¶: nï¼ã€ã‚·ãƒ¼ãƒˆåã€FXã€nan
                                if (cat_str not in ['nan', 'NaN', sheet_name, 'FX', 'è©•ä¾¡é …ç›®']
                                    and 'nï¼' not in cat_str
                                    and 'n=' not in cat_str
                                    and cat_str != sheet_name.replace('åˆ¥', '')):
                                    category_name = cat_str
                                    break
                    break

            if header_row is None:
                continue

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æŒ‡å®šã—ã¦èª­ã¿è¾¼ã¿
            df = pd.read_excel(xl, sheet_name=sheet_name, header=header_row)

            # å¹´åº¦åˆ—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆèª¤æ¤œå‡ºã‚’é˜²ããŸã‚å³å¯†ã«ï¼‰
            year_col = None
            year_exclude_patterns = ['å›ç­”è€…æ•°', 'æœ€æ–°å¹´', 'å›ç­”', 'è€…æ•°', 'å‰å¹´', 'æ˜¨å¹´', 'ä»Šå¹´', 'æ¯å¹´']
            for col in df.columns:
                col_str = str(col)
                if any(pattern in col_str for pattern in year_exclude_patterns):
                    continue
                if col_str == 'å¹´åº¦' or 'å¹´åº¦' in col_str:
                    year_col = col
                    break
                elif col_str == 'å¹´':
                    year_col = col
                    break
                elif len(col_str) == 5 and col_str.endswith('å¹´') and col_str[:4].isdigit():
                    year_col = col
                    break

            # ä¼æ¥­ååˆ—ã‚’æ¢ã™
            company_col = None
            for col in df.columns:
                col_str = str(col)
                if 'ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ä¼æ¥­' in col_str or 'ä¼æ¥­å' in col_str:
                    company_col = col
                    break
            if company_col is None:
                for col in df.columns:
                    col_str = str(col)
                    if 'ä¼æ¥­' in col_str or 'ä¼šç¤¾' in col_str:
                        company_col = col
                        break

            # é †ä½åˆ—ã‚’æ¢ã™ï¼ˆ"é †ä½"ã¨ã„ã†åˆ—åã‚’å„ªå…ˆï¼‰
            rank_col = None
            for col in df.columns:
                col_str = str(col)
                if col_str == 'é †ä½':
                    rank_col = col
                    break
            if rank_col is None:
                for col in df.columns:
                    col_str = str(col)
                    if 'é †ä½' in col_str:
                        rank_col = col
                        break

            # å¾—ç‚¹åˆ—ã‚’æ¢ã™ï¼ˆå„ªå…ˆé †ä½: ã‚¹ã‚³ã‚¢ > åˆè¨ˆ > å¾—ç‚¹ï¼‰
            score_col = None
            for col in df.columns:
                col_str = str(col)
                if col_str == 'ã‚¹ã‚³ã‚¢' or 'ã‚¹ã‚³ã‚¢' in col_str:
                    score_col = col
                    break
            if score_col is None:
                for col in df.columns:
                    if str(col) == 'åˆè¨ˆ':
                        score_col = col
                        break
            if score_col is None:
                for col in df.columns:
                    col_str = str(col)
                    if 'å¾—ç‚¹' in col_str or 'ç‚¹æ•°' in col_str:
                        score_col = col
                        break

            # è©•ä¾¡é …ç›®åˆ—ã‚’æ¢ã™ï¼ˆ1åˆ—ç›®ãŒè©•ä¾¡é …ç›®åã®å ´åˆï¼‰
            eval_item_col = None
            first_col = df.columns[0] if len(df.columns) > 0 else None
            first_col_str = str(first_col) if first_col is not None else ""

            # è©•ä¾¡é …ç›®ã‚·ãƒ¼ãƒˆã®åˆ¤å®š: 1åˆ—ç›®ãŒé †ä½/IDã§ãªãã€è©•ä¾¡é …ç›®åã£ã½ã„å ´åˆ
            if first_col_str not in ['é †ä½', 'ID', 'å¹´åº¦', 'rank', ''] and first_col_str == 'è©•ä¾¡é …ç›®':
                eval_item_col = first_col
            elif 'è©•ä¾¡é …ç›®' in sheet_name and first_col_str not in ['é †ä½', 'ID', 'å¹´åº¦', 'rank', '']:
                eval_item_col = first_col

            if company_col and (rank_col or score_col):
                for _, row in df.iterrows():
                    # å¹´åº¦ã®å–å¾—
                    if year_col and pd.notna(row.get(year_col)):
                        try:
                            year = int(row[year_col])
                            if year < 2000 or year > 2030:
                                year = inferred_year
                        except (ValueError, TypeError):
                            year = inferred_year
                    else:
                        year = inferred_year

                    # ä¼æ¥­åã®å–å¾—
                    company = str(row[company_col]) if pd.notna(row.get(company_col)) else ""
                    if not company or company.lower() in ['nan', 'none', '']:
                        continue

                    # é †ä½ã®å–å¾—
                    try:
                        rank_val = row.get(rank_col) if rank_col else None
                        rank = int(rank_val) if rank_val is not None and pd.notna(rank_val) else None
                    except (ValueError, TypeError):
                        rank = None

                    # å¾—ç‚¹ã®å–å¾—
                    try:
                        score_val = row.get(score_col) if score_col else None
                        score = float(score_val) if score_val is not None and pd.notna(score_val) else None
                    except (ValueError, TypeError):
                        score = None

                    # è©•ä¾¡é …ç›®åã®å–å¾—
                    eval_item_name = None
                    if eval_item_col:
                        try:
                            val = row.get(eval_item_col)
                            eval_item_name = str(val) if pd.notna(val) and str(val) not in ['nan', 'None', 'è©•ä¾¡é …ç›®'] else None
                        except:
                            eval_item_name = None

                    # ã‚·ãƒ¼ãƒˆç¨®åˆ¥ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
                    # 1. ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ç³»
                    if 'ç·åˆ' in sheet_name or 'å¯¾è±¡ä¼æ¥­' in sheet_name:
                        if year not in overall_data:
                            overall_data[year] = []
                        overall_data[year].append({
                            "rank": rank,
                            "company": company,
                            "score": score
                        })

                    # 2. è©•ä¾¡é …ç›®ã‚·ãƒ¼ãƒˆï¼ˆ1åˆ—ç›®ã«é …ç›®åãŒã‚ã‚‹ï¼‰
                    elif eval_item_name and ('è©•ä¾¡é …ç›®' in sheet_name or eval_item_col):
                        if eval_item_name not in item_data:
                            item_data[eval_item_name] = {}
                        if year not in item_data[eval_item_name]:
                            item_data[eval_item_name][year] = []
                        item_data[eval_item_name][year].append({
                            "rank": rank,
                            "company": company,
                            "score": score
                        })

                    # 3. éƒ¨é–€åˆ¥ã‚·ãƒ¼ãƒˆï¼ˆæ¥­æ…‹åˆ¥ã€æŠ•è³‡ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥ã€åˆ©ç”¨ãƒãƒ£ãƒ¼ãƒˆåˆ¥ã€ãƒ¬ãƒ™ãƒ«åˆ¥ã€ã‚µãƒãƒ¼ãƒˆåˆ¥ï¼‰
                    elif any(x in sheet_name for x in ['æ¥­æ…‹', 'æŠ•è³‡ã‚¹ã‚¿ã‚¤ãƒ«', 'åˆ©ç”¨ãƒãƒ£ãƒ¼ãƒˆ', 'ãƒãƒ£ãƒ¼ãƒˆ', 'ãƒ¬ãƒ™ãƒ«', 'ã‚µãƒãƒ¼ãƒˆ', 'åˆ¥']):
                        # ã‚«ãƒ†ã‚´ãƒªåãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ã‚·ãƒ¼ãƒˆå
                        dept_name = category_name if category_name else sheet_name.replace('åˆ¥', '')
                        if dept_name not in dept_data:
                            dept_data[dept_name] = {}
                        if year not in dept_data[dept_name]:
                            dept_data[dept_name][year] = []
                        dept_data[dept_name][year].append({
                            "rank": rank,
                            "company": company,
                            "score": score
                        })

        return overall_data, item_data, dept_data, None
    except Exception as e:
        import traceback
        return None, None, None, f"{str(e)}\n{traceback.format_exc()}"


def merge_data(uploaded_data, scraped_data):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å„ªå…ˆï¼‰"""
    merged = {}

    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«
    for year, data in scraped_data.items():
        merged[year] = data

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã§ä¸Šæ›¸ãï¼ˆå„ªå…ˆï¼‰
    for year, data in uploaded_data.items():
        merged[year] = data

    return merged


def merge_nested_data(uploaded_data, scraped_data):
    """è©•ä¾¡é …ç›®åˆ¥ãƒ»éƒ¨é–€åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ"""
    merged = {}

    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«
    for key, year_data in scraped_data.items():
        if key not in merged:
            merged[key] = {}
        if isinstance(year_data, dict):
            for year, data in year_data.items():
                merged[key][year] = data

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã§ä¸Šæ›¸ãï¼ˆå„ªå…ˆï¼‰
    for key, year_data in uploaded_data.items():
        if key not in merged:
            merged[key] = {}
        if isinstance(year_data, dict):
            for year, data in year_data.items():
                merged[key][year] = data

    return merged


def display_historical_summary(records, prefix=""):
    """æ­´ä»£è¨˜éŒ²ãƒ»é€£ç¶šè¨˜éŒ²ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    if not records:
        return

    summary = records.get("summary", {})
    if summary:
        col1, col2, col3 = st.columns(3)
        with col1:
            if summary.get("max_consecutive"):
                mc = summary["max_consecutive"]
                st.metric(
                    f"{prefix}ğŸ¥‡ æœ€é•·é€£ç¶š1ä½",
                    f"{mc['company']}",
                    f"{mc['years']}å¹´é€£ç¶š ({mc['start_year']}ã€œ{mc['end_year']})"
                )
        with col2:
            if summary.get("all_time_high"):
                ath = summary["all_time_high"]
                st.metric(
                    f"{prefix}ğŸ“ˆ éå»æœ€é«˜å¾—ç‚¹",
                    f"{ath['score']}ç‚¹",
                    f"{ath['company']} ({ath['year']}å¹´)"
                )
        with col3:
            if summary.get("most_wins"):
                mw = summary["most_wins"]
                st.metric(
                    f"{prefix}ğŸ† æœ€å¤š1ä½ç²å¾—",
                    f"{mw['company']}",
                    f"{mw['wins']}å› / {mw['total_years']}å¹´ä¸­"
                )


def display_consecutive_wins_compact(records):
    """é€£ç¶š1ä½è¨˜éŒ²ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«è¡¨ç¤º"""
    consecutive = records.get("consecutive_wins", [])
    if consecutive:
        st.markdown("**ğŸ¥‡ é€£ç¶š1ä½è¨˜éŒ²ï¼ˆä¸Šä½5ä»¶ï¼‰**")
        cons_df = pd.DataFrame([
            {
                "ä¼æ¥­å": r["company"],
                "é€£ç¶šå¹´æ•°": f"{r['years']}å¹´",
                "æœŸé–“": f"{r['start_year']}ã€œ{r['end_year']}",
                "ç¶™ç¶šä¸­": "âœ…" if r.get("is_current") else ""
            }
            for r in consecutive[:5]
        ])
        st.dataframe(cons_df, use_container_width=True, hide_index=True)


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦Â®èª¿æŸ» TOPICSã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“°",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ“° ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦Â®èª¿æŸ» TOPICSã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ")
st.warning("âš ï¸ **æ³¨æ„äº‹é …**: Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚æƒ…å ±ã®æ­£ç¢ºæ€§ã¯æ‹…å½“è€…ãŒå¿…ãšç¢ºèªã—ã¦ãã ã•ã„ã€‚")
st.markdown("ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®è¦‹å‡ºã—ãƒˆãƒ”ãƒƒã‚¯ã‚¹å€™è£œã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°é¸æŠ
ranking_options = {
    # === é‡‘èãƒ»æŠ•è³‡ ===
    "FXï¼ˆé¡§å®¢æº€è¶³åº¦ï¼‰": "_fx",
    "FXï¼ˆFPè©•ä¾¡ï¼‰": "_fx@type02",
    "éŠ€è¡Œã‚«ãƒ¼ãƒ‰ãƒ­ãƒ¼ãƒ³": "card-loan",
    "ãƒãƒ³ãƒãƒ³ã‚¯ã‚«ãƒ¼ãƒ‰ãƒ­ãƒ¼ãƒ³": "card-loan/nonbank",
    "ãƒãƒƒãƒˆè¨¼åˆ¸ï¼ˆé¡§å®¢æº€è¶³åº¦ï¼‰": "_certificate",
    "ãƒãƒƒãƒˆè¨¼åˆ¸ï¼ˆFPè©•ä¾¡ï¼‰": "_certificate@type02",
    "iDeCoè¨¼åˆ¸ä¼šç¤¾": "ideco",
    "NISAï¼ˆè¨¼åˆ¸ä¼šç¤¾ï¼‰": "_nisa",
    "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰": "creditcard",
    # === ä¿é™º ===
    "è‡ªå‹•è»Šä¿é™ºï¼ˆãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå‹ï¼‰": "_insurance",
    "è‡ªå‹•è»Šä¿é™ºï¼ˆä»£ç†åº—å‹ï¼‰": "_insurance@type02",
    "è‡ªå‹•è»Šä¿é™ºï¼ˆFPæ¨å¥¨ï¼‰": "_insurance@type03",
    "ç”Ÿå‘½ä¿é™º": "life-insurance",
    "ä¿é™ºã‚·ãƒ§ãƒƒãƒ—ï¼ˆFPï¼‰": "_hokenshop",
    # === é€šä¿¡ ===
    "æºå¸¯ã‚­ãƒ£ãƒªã‚¢": "mobile-carrier",
    "æ ¼å®‰SIM": "mvno",
    "æ ¼å®‰SIMï¼ˆSIMã®ã¿ï¼‰": "mvno/sim",
    "æ ¼å®‰ã‚¹ãƒãƒ›": "mvno/sp",
    # === æ•™è‚²ï¼ˆè‹±ä¼šè©±ï¼‰ ===
    "è‹±ä¼šè©±ã‚¹ã‚¯ãƒ¼ãƒ«": "english-school",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è‹±ä¼šè©±": "online-english",
    "å­ã©ã‚‚è‹±èªæ•™å®¤ï¼ˆå¹¼å…ï¼‰": "kids-english/preschooler",
    "å­ã©ã‚‚è‹±èªæ•™å®¤ï¼ˆå°å­¦ç”Ÿï¼‰": "kids-english/grade-schooler",
    # === æ•™è‚²ï¼ˆå­¦ç¿’ï¼‰ ===
    "å®¶åº­æ•™å¸«": "tutor",
    "é€šä¿¡æ•™è‚²ï¼ˆé«˜æ ¡ç”Ÿï¼‰": "online-study/highschool",
    "é€šä¿¡æ•™è‚²ï¼ˆä¸­å­¦ç”Ÿï¼‰": "online-study/junior-hs",
    "é€šä¿¡æ•™è‚²ï¼ˆå°å­¦ç”Ÿï¼‰": "online-study/elementary",
    # === æ•™è‚²ï¼ˆã‚¹ãƒãƒ¼ãƒ„ï¼‰ ===
    "ã‚­ãƒƒã‚ºã‚¹ã‚¤ãƒŸãƒ³ã‚°ã‚¹ã‚¯ãƒ¼ãƒ«ï¼ˆå¹¼å…ï¼‰": "kids-swimming/preschooler",
    "ã‚­ãƒƒã‚ºã‚¹ã‚¤ãƒŸãƒ³ã‚°ã‚¹ã‚¯ãƒ¼ãƒ«ï¼ˆå°å­¦ç”Ÿï¼‰": "kids-swimming/grade-schooler",
    # === è»¢è·ãƒ»äººæ ===
    "è»¢è·ã‚µã‚¤ãƒˆ": "recruit",
    "è»¢è·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ": "_agent",
    "æ´¾é£ä¼šç¤¾ï¼ˆè£½é€ æ¥­ï¼‰": "_staffing_manufacture",
    # === ä½å®…ãƒ»ä¸å‹•ç”£ ===
    "ãƒã‚¦ã‚¹ãƒ¡ãƒ¼ã‚«ãƒ¼ï¼ˆæ³¨æ–‡ä½å®…ï¼‰": "house-maker",
    "å»ºå£²ä½å®…ãƒ“ãƒ«ãƒ€ãƒ¼": "new-ready-built-house",
    "å»ºå£²ä½å®…ï¼ˆãƒ‘ãƒ¯ãƒ¼ãƒ“ãƒ«ãƒ€ãƒ¼ï¼‰": "new-ready-built-house/powerbuilder",
    "æ–°ç¯‰åˆ†è­²ãƒãƒ³ã‚·ãƒ§ãƒ³": "new-condominiums",
    # === ç”Ÿæ´»ã‚µãƒ¼ãƒ“ã‚¹ ===
    "å¼•è¶Šã—ä¼šç¤¾": "_move",
    "é£Ÿæå®…é…": "food-delivery",
    "ãƒŸãƒ¼ãƒ«ã‚­ãƒƒãƒˆ": "food-delivery/meal-kit",
    "å­ã©ã‚‚è¦‹å®ˆã‚ŠGPS": "child-gps",
    # === ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ ===
    "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¯ãƒ©ãƒ–": "_fitness",
    "24æ™‚é–“ã‚¸ãƒ ": "_fitness/24hours",
    # === ãã®ä»– ===
    "ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›": "custom"
}

selected_ranking = st.sidebar.selectbox(
    "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’é¸æŠ",
    list(ranking_options.keys())
)

# ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›ã®å ´åˆ
if selected_ranking == "ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›":
    ranking_slug = st.sidebar.text_input(
        "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®URLå",
        placeholder="ä¾‹: mobile-carrier"
    )
    ranking_name = st.sidebar.text_input(
        "ãƒ©ãƒ³ã‚­ãƒ³ã‚°åï¼ˆè¡¨ç¤ºç”¨ï¼‰",
        placeholder="ä¾‹: æºå¸¯ã‚­ãƒ£ãƒªã‚¢"
    )
else:
    ranking_slug = ranking_options[selected_ranking]
    ranking_name = selected_ranking

# å¹´åº¦é¸æŠ
# æ³¨æ„: current_yearã¯Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®æœ€æ–°å¹´åº¦ï¼ˆã‚ªãƒªã‚³ãƒ³ã‚µã‚¤ãƒˆã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æœ€æ–°ï¼‰
# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å¹´åº¦ã¯åˆ¥é€”æŒ‡å®šå¯èƒ½
current_year = 2025  # Webã‚µã‚¤ãƒˆã®æœ€æ–°å¹´åº¦
start_year = 2006

year_option = st.sidebar.radio(
    "éå»ãƒ‡ãƒ¼ã‚¿å–å¾—ç¯„å›²",
    ["ç›´è¿‘3å¹´", "ç›´è¿‘5å¹´", "å…¨å¹´åº¦ï¼ˆ2006å¹´ã€œï¼‰", "ã‚«ã‚¹ã‚¿ãƒ ç¯„å›²"]
)

if year_option == "ç›´è¿‘3å¹´":
    year_range = (current_year - 2, current_year)
elif year_option == "ç›´è¿‘5å¹´":
    year_range = (current_year - 4, current_year)
elif year_option == "å…¨å¹´åº¦ï¼ˆ2006å¹´ã€œï¼‰":
    year_range = (start_year, current_year)
else:
    year_range = st.sidebar.slider(
        "å¹´åº¦ç¯„å›²ã‚’é¸æŠ",
        min_value=start_year,
        max_value=current_year,
        value=(current_year - 4, current_year)
    )

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
uploaded_file = st.sidebar.file_uploader(
    "æœ€æ–°ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["xlsx", "xls"],
    help="æœ€æ–°ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€éå»ãƒ‡ãƒ¼ã‚¿ã¨çµ±åˆã—ã¦åˆ†æã—ã¾ã™"
)

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å¹´åº¦æŒ‡å®š
upload_year = None
if uploaded_file:
    st.sidebar.success(f"âœ… {uploaded_file.name}")
    upload_year = st.sidebar.number_input(
        "ğŸ“… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å¹´åº¦",
        min_value=2006,
        max_value=2030,
        value=2026,
        help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å¹´åº¦ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹: 2026å¹´ç™ºè¡¨ãƒ‡ãƒ¼ã‚¿ãªã‚‰2026ï¼‰"
    )
    st.sidebar.info(f"ğŸ“Œ **{upload_year}å¹´**ã®ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã€ãã‚Œä»¥å¤–ã®å¹´åº¦ã¯Webã‹ã‚‰å–å¾—ã—ã¦çµ±åˆã—ã¾ã™")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'results_data' not in st.session_state:
    st.session_state.results_data = None

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸš€ TOPICSå‡ºã—å®Ÿè¡Œ", type="primary", use_container_width=True):

    if not ranking_slug:
        st.error("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®URLåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()

        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢
        debug_expander = st.expander("ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°", expanded=False)
        debug_logs = []

        def log(message):
            debug_logs.append(message)
            with debug_expander:
                st.text("\n".join(debug_logs))

        try:
            uploaded_overall = {}
            uploaded_item = {}
            uploaded_dept = {}
            uploaded_years = set()

            # Step 1: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°è§£æ
            if uploaded_file:
                status_text.text("ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­...")
                progress_bar.progress(10)

                uploaded_overall, uploaded_item, uploaded_dept, error = parse_uploaded_excel(uploaded_file, upload_year)

                if error:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {error}")
                    st.stop()

                if uploaded_overall is None:
                    uploaded_overall = {}
                if uploaded_item is None:
                    uploaded_item = {}
                if uploaded_dept is None:
                    uploaded_dept = {}

                uploaded_years = set(uploaded_overall.keys())
                log(f"[OK] ãƒ•ã‚¡ã‚¤ãƒ«è§£æå®Œäº†: {uploaded_file.name}")
                log(f"  - ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(uploaded_overall)}å¹´åˆ†")
                log(f"  - å«ã¾ã‚Œã‚‹å¹´åº¦: {sorted(uploaded_years)}")
                for year, data in uploaded_overall.items():
                    log(f"    {year}å¹´: {len(data)}ç¤¾")
                    if data:
                        top = data[0]
                        log(f"      1ä½: {top.get('company')} ({top.get('score')}ç‚¹)")
                log(f"  - è©•ä¾¡é …ç›®åˆ¥: {len(uploaded_item)}é …ç›®")
                for item_name in list(uploaded_item.keys())[:3]:
                    log(f"    [{item_name}]")
                log(f"  - éƒ¨é–€åˆ¥: {len(uploaded_dept)}éƒ¨é–€")
                for dept_name in list(uploaded_dept.keys())[:3]:
                    log(f"    [{dept_name}]")

            # Step 2: Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            status_text.text("ğŸŒ Webã‹ã‚‰éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            progress_bar.progress(20)

            log(f"[INFO] ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–: {ranking_slug} ({ranking_name})")
            scraper = OriconScraper(ranking_slug, ranking_name)
            subpath_info = f" + subpath: {scraper.subpath}" if scraper.subpath else ""
            log(f"[INFO] URL prefix: {scraper.url_prefix}{subpath_info}")

            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡å¹´åº¦ã‚’æ±ºå®š
            # - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹å¹´åº¦ã¯é™¤å¤–
            # - Webã‚µã‚¤ãƒˆã®æœ€æ–°å¹´åº¦ï¼ˆcurrent_year=2025ï¼‰ã‚’è¶…ãˆã‚‹å¹´åº¦ã¯é™¤å¤–
            scrape_years = []
            effective_end_year = min(year_range[1], current_year)  # Webã‚µã‚¤ãƒˆã®æœ€æ–°å¹´åº¦ã‚’è¶…ãˆãªã„
            for y in range(year_range[0], effective_end_year + 1):
                if y not in uploaded_years:
                    scrape_years.append(y)

            log(f"[INFO] å¹´åº¦ç¯„å›²è¨­å®š: {year_range[0]}ã€œ{year_range[1]}")
            log(f"[INFO] Webã‚µã‚¤ãƒˆæœ€æ–°å¹´åº¦: {current_year}")
            log(f"[INFO] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¹´åº¦: {sorted(uploaded_years) if uploaded_years else 'ãªã—'}")

            if scrape_years:
                log(f"[INFO] ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡å¹´åº¦: {scrape_years}")
                scrape_range = (min(scrape_years), max(scrape_years))
            else:
                log(f"[INFO] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã§å…¨å¹´åº¦ã‚«ãƒãƒ¼æ¸ˆã¿ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                scrape_range = None

            scraped_overall = {}
            scraped_item = {}
            scraped_dept = {}

            if scrape_range:
                status_text.text(f"ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ä¸­... ({scrape_range[0]}å¹´ã€œ{scrape_range[1]}å¹´)")
                progress_bar.progress(30)

                scraped_overall = scraper.get_overall_rankings(scrape_range)
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿å¹´åº¦ã‚’é™¤å¤–
                scraped_overall = {y: d for y, d in scraped_overall.items() if y not in uploaded_years}
                log(f"[OK] ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(scraped_overall)}å¹´åˆ†å–å¾—")
                for year, data in scraped_overall.items():
                    log(f"  - {year}å¹´: {len(data)}ç¤¾")
                progress_bar.progress(45)

                status_text.text(f"ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
                scraped_item = scraper.get_evaluation_items(scrape_range)
                log(f"[OK] è©•ä¾¡é …ç›®åˆ¥: {len(scraped_item)}é …ç›®")
                progress_bar.progress(60)

                status_text.text(f"ğŸ·ï¸ éƒ¨é–€åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
                scraped_dept = scraper.get_departments(scrape_range)
                log(f"[OK] éƒ¨é–€åˆ¥: {len(scraped_dept)}éƒ¨é–€")
                progress_bar.progress(70)

            used_urls = scraper.used_urls if scrape_range else None

            # Step 3: ãƒ‡ãƒ¼ã‚¿çµ±åˆ
            status_text.text("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆä¸­...")
            progress_bar.progress(75)

            overall_data = merge_data(uploaded_overall, scraped_overall)
            item_data = merge_nested_data(uploaded_item, scraped_item)
            dept_data = merge_nested_data(uploaded_dept, scraped_dept)

            log(f"[OK] ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†")
            log(f"  - ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(overall_data)}å¹´åˆ†ï¼ˆçµ±åˆå¾Œï¼‰")
            log(f"    â”” ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {len(uploaded_overall)}å¹´åˆ†")
            log(f"    â”” ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°: {len(scraped_overall)}å¹´åˆ†")

            # Step 4: åˆ†æå®Ÿè¡Œ
            status_text.text("ğŸ” TOPICSåˆ†æä¸­...")
            analyzer = TopicsAnalyzer(overall_data, item_data, ranking_name)
            topics = analyzer.analyze()
            progress_bar.progress(85)

            # Step 5: æ­´ä»£è¨˜éŒ²ãƒ»å¾—ç‚¹æ¨ç§»åˆ†æ
            status_text.text("ğŸ“ˆ æ­´ä»£è¨˜éŒ²ãƒ»å¾—ç‚¹æ¨ç§»ã‚’åˆ†æä¸­...")
            historical_analyzer = HistoricalAnalyzer(overall_data, item_data, dept_data, ranking_name)
            historical_data = historical_analyzer.analyze_all()
            progress_bar.progress(95)

            # å®Œäº†
            status_text.text("âœ… å®Œäº†!")
            progress_bar.progress(100)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
            st.session_state.results_data = {
                'ranking_name': ranking_name,
                'overall_data': overall_data,
                'item_data': item_data,
                'dept_data': dept_data,
                'historical_data': historical_data,
                'topics': topics,
                'used_urls': used_urls,
                'uploaded_years': list(uploaded_years),
                'scraped_years': list(scraped_overall.keys()) if scraped_overall else []
            }

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.exception(e)

# çµæœè¡¨ç¤ºï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ï¼‰
if st.session_state.results_data:
    data = st.session_state.results_data
    ranking_name = data['ranking_name']
    overall_data = data['overall_data']
    item_data = data['item_data']
    dept_data = data['dept_data']
    historical_data = data['historical_data']
    topics = data['topics']
    used_urls = data.get('used_urls')
    uploaded_years = data.get('uploaded_years', [])
    scraped_years = data.get('scraped_years', [])

    # çµæœè¡¨ç¤º
    st.success(f"âœ… {ranking_name}ã®TOPICSå‡ºã—ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±
    if uploaded_years or scraped_years:
        col_info1, col_info2 = st.columns(2)
        with col_info1:
            if uploaded_years:
                st.info(f"ğŸ“ **ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿**: {sorted(uploaded_years)}å¹´")
        with col_info2:
            if scraped_years:
                st.info(f"ğŸŒ **Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: {sorted(scraped_years)}å¹´")

    # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ï¼ˆå¤§ããç›®ç«‹ã¤ã‚ˆã†ã«ï¼‰
    st.markdown("---")
    excel_data = create_excel_export(
        ranking_name,
        overall_data,
        item_data,
        dept_data,
        historical_data,
        used_urls
    )

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.download_button(
            label="ğŸ“¥ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=excel_data,
            file_name=f"{ranking_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary",
            use_container_width=True,
            key="excel_download_main"
        )
    st.markdown("---")

    # ã‚¿ãƒ–ã§çµæœè¡¨ç¤ºï¼ˆæ–°ã—ã„æ§‹æˆï¼‰
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "â­ æ¨å¥¨TOPICS",
        "ğŸ¯ è¦‹å‡ºã—æ¡ˆ",
        "ğŸ† æ­´ä»£è¨˜éŒ²ãƒ»å¾—ç‚¹æ¨ç§»",
        "ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°",
        "ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥",
        "ğŸ·ï¸ éƒ¨é–€åˆ¥",
        "ğŸ“ å‚è€ƒè³‡æ–™"
    ])

    with tab1:
        st.header("â­ æ¨å¥¨TOPICS")
        for i, topic in enumerate(topics["recommended"], 1):
            importance = topic.get("importance", "é‡è¦")
            st.markdown(f"### {i}. [{importance}] {topic['title']}")
            st.markdown(f"- **æ ¹æ‹ **: {topic['evidence']}")
            st.markdown(f"- **ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: {'â˜…' * topic.get('impact', 3)}")
            st.divider()

        if topics.get("other"):
            st.subheader("ğŸ“Š ãã®ä»–ã®TOPICSå€™è£œ")
            for topic in topics["other"]:
                st.markdown(f"- {topic}")

    with tab2:
        st.header("ğŸ¯ è¦‹å‡ºã—æ¡ˆ")
        for i, headline in enumerate(topics.get("headlines", []), 1):
            st.markdown(f"**ãƒ‘ã‚¿ãƒ¼ãƒ³{i}**: {headline}")

        # ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆ
        st.subheader("ğŸ“‹ ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆ")
        copy_text = "\n".join([
            "ã€æ¨å¥¨TOPICSã€‘",
            *[f"{i}. {t['title']}" for i, t in enumerate(topics["recommended"], 1)],
            "",
            "ã€è¦‹å‡ºã—æ¡ˆã€‘",
            *[f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i}: {h}" for i, h in enumerate(topics.get("headlines", []), 1)]
        ])
        st.text_area("ã‚³ãƒ”ãƒ¼ç”¨", copy_text, height=300, label_visibility="collapsed")

    with tab3:
        st.header("ğŸ† æ­´ä»£è¨˜éŒ²ãƒ»å¾—ç‚¹æ¨ç§»")
        records = historical_data.get("historical_records", {})
        trends = historical_data.get("score_trends", {})

        if records:
            # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            display_historical_summary(records)
            st.divider()

            # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            col_left, col_right = st.columns(2)

            with col_left:
                # é€£ç¶š1ä½è¨˜éŒ²
                st.subheader("ğŸ¥‡ é€£ç¶š1ä½è¨˜éŒ²")
                consecutive = records.get("consecutive_wins", [])
                if consecutive:
                    cons_df = pd.DataFrame([
                        {
                            "ä¼æ¥­å": r["company"],
                            "é€£ç¶šå¹´æ•°": f"{r['years']}å¹´",
                            "æœŸé–“": f"{r['start_year']}ã€œ{r['end_year']}",
                            "ç¶™ç¶šä¸­": "âœ…" if r.get("is_current") else ""
                        }
                        for r in consecutive[:10]
                    ])
                    st.dataframe(cons_df, use_container_width=True, hide_index=True)

                # éå»æœ€é«˜å¾—ç‚¹
                st.subheader("ğŸ“ˆ éå»æœ€é«˜å¾—ç‚¹TOP10")
                highest = records.get("highest_scores", [])
                if highest:
                    high_df = pd.DataFrame([
                        {
                            "é †ä½": i,
                            "ä¼æ¥­å": r["company"],
                            "å¾—ç‚¹": f"{r['score']}ç‚¹",
                            "å¹´åº¦": f"{r['year']}å¹´",
                            "ãã®å¹´ã®é †ä½": f"{r['rank']}ä½"
                        }
                        for i, r in enumerate(highest[:10], 1)
                    ])
                    st.dataframe(high_df, use_container_width=True, hide_index=True)

            with col_right:
                # æœ€å¤š1ä½ç²å¾—
                st.subheader("ğŸ† 1ä½ç²å¾—å›æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                most_wins = records.get("most_wins", [])
                if most_wins:
                    wins_df = pd.DataFrame([
                        {
                            "ä¼æ¥­å": r["company"],
                            "1ä½å›æ•°": f"{r['wins']}å›",
                            "ç²å¾—ç‡": f"{r['wins']/r['total_years']*100:.1f}%",
                            "ç²å¾—å¹´": ", ".join(map(str, r["years"]))
                        }
                        for r in most_wins[:10]
                    ])
                    st.dataframe(wins_df, use_container_width=True, hide_index=True)

                # å¹´åº¦åˆ¥1ä½ã®æ¨ç§»
                st.subheader("ğŸ¥‡ å¹´åº¦åˆ¥1ä½ã®æ¨ç§»")
                top_by_year = trends.get("top_score_by_year", {})
                if top_by_year:
                    top_df = pd.DataFrame([
                        {
                            "å¹´åº¦": year,
                            "1ä½ä¼æ¥­": top_by_year[year]["company"],
                            "å¾—ç‚¹": f"{top_by_year[year]['score']}ç‚¹"
                        }
                        for year in sorted(top_by_year.keys(), reverse=True)
                    ])
                    st.dataframe(top_df, use_container_width=True, hide_index=True)

        st.divider()

        # å¾—ç‚¹æ¨ç§»ã‚°ãƒ©ãƒ•
        if trends and trends.get("years"):
            years = trends["years"]

            # å¹´åº¦åˆ¥å¹³å‡å¾—ç‚¹
            st.subheader("ğŸ“Š å¹´åº¦åˆ¥å¹³å‡å¾—ç‚¹ã®æ¨ç§»")
            avg_scores = trends.get("average_scores", {})
            if avg_scores:
                avg_df = pd.DataFrame([
                    {"å¹´åº¦": year, "å¹³å‡å¾—ç‚¹": score}
                    for year, score in sorted(avg_scores.items())
                ])
                import altair as alt
                chart = alt.Chart(avg_df).mark_line(point=True).encode(
                    x=alt.X('å¹´åº¦:O', title='å¹´åº¦'),
                    y=alt.Y('å¹³å‡å¾—ç‚¹:Q', title='å¹³å‡å¾—ç‚¹', scale=alt.Scale(domain=[60, 80]))
                ).properties(height=300)
                st.altair_chart(chart, use_container_width=True)

            # ä¸Šä½ä¼æ¥­ã®å¾—ç‚¹æ¨ç§»
            st.subheader("ğŸ“ˆ ä¸Šä½ä¼æ¥­ã®å¾—ç‚¹æ¨ç§»")
            top_companies = trends.get("top_companies", [])[:5]
            companies_data = trends.get("companies", {})

            if top_companies and companies_data:
                chart_data = []
                for company in top_companies:
                    if company in companies_data:
                        for year in years:
                            score = companies_data[company].get(year, {}).get("score")
                            if score:
                                chart_data.append({
                                    "å¹´åº¦": str(year),
                                    "ä¼æ¥­å": company,
                                    "å¾—ç‚¹": score
                                })

                if chart_data:
                    chart_df = pd.DataFrame(chart_data)
                    chart = alt.Chart(chart_df).mark_line(point=True).encode(
                        x=alt.X('å¹´åº¦:O', title='å¹´åº¦'),
                        y=alt.Y('å¾—ç‚¹:Q', title='å¾—ç‚¹', scale=alt.Scale(domain=[60, 80])),
                        color=alt.Color('ä¼æ¥­å:N', title='ä¼æ¥­å'),
                        tooltip=['å¹´åº¦', 'ä¼æ¥­å', 'å¾—ç‚¹']
                    ).properties(height=400)
                    st.altair_chart(chart, use_container_width=True)

            # è©•ä¾¡é …ç›®åˆ¥ã®é€£ç¶š1ä½
            st.subheader("ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ é€£ç¶š1ä½è¨˜éŒ²")
            item_trends = historical_data.get("item_trends", {})
            if item_trends:
                item_records = []
                for item_name, data in item_trends.items():
                    for streak in data.get("consecutive_wins", []):
                        if streak.get("years", 0) >= 2:
                            item_records.append({
                                "è©•ä¾¡é …ç›®": item_name,
                                "ä¼æ¥­å": streak["company"],
                                "é€£ç¶šå¹´æ•°": f"{streak['years']}å¹´",
                                "æœŸé–“": f"{streak['start']}ã€œ{streak['end']}",
                                "ç¶™ç¶šä¸­": "âœ…" if streak.get("is_current") else ""
                            })
                if item_records:
                    item_records.sort(key=lambda x: -int(x["é€£ç¶šå¹´æ•°"].replace("å¹´", "")))
                    st.dataframe(pd.DataFrame(item_records[:15]), use_container_width=True, hide_index=True)

            # éƒ¨é–€åˆ¥ã®é€£ç¶š1ä½
            st.subheader("ğŸ·ï¸ éƒ¨é–€åˆ¥ é€£ç¶š1ä½è¨˜éŒ²")
            dept_trends = historical_data.get("dept_trends", {})
            if dept_trends:
                dept_records = []
                for dept_name, data in dept_trends.items():
                    for streak in data.get("consecutive_wins", []):
                        if streak.get("years", 0) >= 2:
                            dept_records.append({
                                "éƒ¨é–€": dept_name,
                                "ä¼æ¥­å": streak["company"],
                                "é€£ç¶šå¹´æ•°": f"{streak['years']}å¹´",
                                "æœŸé–“": f"{streak['start']}ã€œ{streak['end']}",
                                "ç¶™ç¶šä¸­": "âœ…" if streak.get("is_current") else ""
                            })
                if dept_records:
                    dept_records.sort(key=lambda x: -int(x["é€£ç¶šå¹´æ•°"].replace("å¹´", "")))
                    st.dataframe(pd.DataFrame(dept_records[:15]), use_container_width=True, hide_index=True)

    with tab4:
        st.header("ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´è©³ç´°ï¼‰")

        # ãƒˆãƒƒãƒ—ã«æ­´ä»£è¨˜éŒ²ã‚’è¡¨ç¤º
        records = historical_data.get("historical_records", {})
        if records:
            display_historical_summary(records)
            display_consecutive_wins_compact(records)
            st.divider()

        if overall_data:
            # å¹´åº¦ã”ã¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¯ï¼‰
            for year in sorted(overall_data.keys(), reverse=True):
                source_mark = "ğŸ“" if year in uploaded_years else "ğŸŒ"
                with st.expander(f"{source_mark} {year}å¹´", expanded=(year == max(overall_data.keys()))):
                    df = pd.DataFrame(overall_data[year])
                    st.dataframe(df, use_container_width=True)

            # çµŒå¹´æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«
            st.subheader("ğŸ“ˆ çµŒå¹´æ¯”è¼ƒï¼ˆå…¨ç¤¾å¾—ç‚¹æ¨ç§»ï¼‰")

            companies = set()
            for year_data in overall_data.values():
                for item in year_data:
                    companies.add(item.get("company", ""))

            comparison_data = []
            for company in sorted(companies):
                row = {"ä¼æ¥­å": company}
                for year in sorted(overall_data.keys()):
                    score = "-"
                    rank = "-"
                    for item in overall_data[year]:
                        if item.get("company") == company:
                            score = item.get("score", "-")
                            rank = item.get("rank", "-")
                            break
                    row[f"{year}å¹´å¾—ç‚¹"] = score
                    row[f"{year}å¹´é †ä½"] = rank
                comparison_data.append(row)

            if comparison_data:
                st.dataframe(pd.DataFrame(comparison_data), use_container_width=True)

    with tab5:
        st.header("ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´ï¼‰")

        # ãƒˆãƒƒãƒ—ã«è©•ä¾¡é …ç›®åˆ¥ã®é€£ç¶š1ä½è¨˜éŒ²
        item_trends = historical_data.get("item_trends", {})
        if item_trends:
            st.subheader("ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ é€£ç¶š1ä½è¨˜éŒ²ï¼ˆä¸Šä½5ä»¶ï¼‰")
            item_records = []
            for item_name, data in item_trends.items():
                for streak in data.get("consecutive_wins", []):
                    if streak.get("years", 0) >= 2:
                        item_records.append({
                            "è©•ä¾¡é …ç›®": item_name,
                            "ä¼æ¥­å": streak["company"],
                            "é€£ç¶šå¹´æ•°": f"{streak['years']}å¹´",
                            "æœŸé–“": f"{streak['start']}ã€œ{streak['end']}",
                            "ç¶™ç¶šä¸­": "âœ…" if streak.get("is_current") else ""
                        })
            if item_records:
                item_records.sort(key=lambda x: -int(x["é€£ç¶šå¹´æ•°"].replace("å¹´", "")))
                st.dataframe(pd.DataFrame(item_records[:5]), use_container_width=True, hide_index=True)
            st.divider()

        if item_data:
            for item_name, year_data in item_data.items():
                with st.expander(f"ğŸ“Œ {item_name}", expanded=False):
                    if isinstance(year_data, dict):
                        for year in sorted(year_data.keys(), reverse=True):
                            st.markdown(f"**{year}å¹´**")
                            df = pd.DataFrame(year_data[year])
                            st.dataframe(df, use_container_width=True)

                        if len(year_data) > 1:
                            st.markdown("**ğŸ“ˆ 1ä½ã®æ¨ç§»**")
                            history = []
                            for year in sorted(year_data.keys(), reverse=True):
                                if year_data[year]:
                                    top = year_data[year][0]
                                    history.append({
                                        "å¹´åº¦": year,
                                        "1ä½": top.get("company", "-"),
                                        "å¾—ç‚¹": top.get("score", "-")
                                    })
                            if history:
                                st.dataframe(pd.DataFrame(history), use_container_width=True)
                    else:
                        df = pd.DataFrame(year_data)
                        st.dataframe(df, use_container_width=True)
        else:
            st.info("è©•ä¾¡é …ç›®åˆ¥ãƒ‡ãƒ¼ã‚¿ã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    with tab6:
        st.header("ğŸ·ï¸ éƒ¨é–€åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆçµŒå¹´ï¼‰")

        # ãƒˆãƒƒãƒ—ã«éƒ¨é–€åˆ¥ã®é€£ç¶š1ä½è¨˜éŒ²
        dept_trends = historical_data.get("dept_trends", {})
        if dept_trends:
            st.subheader("ğŸ·ï¸ éƒ¨é–€åˆ¥ é€£ç¶š1ä½è¨˜éŒ²ï¼ˆä¸Šä½5ä»¶ï¼‰")
            dept_records = []
            for dept_name, data in dept_trends.items():
                for streak in data.get("consecutive_wins", []):
                    if streak.get("years", 0) >= 2:
                        dept_records.append({
                            "éƒ¨é–€": dept_name,
                            "ä¼æ¥­å": streak["company"],
                            "é€£ç¶šå¹´æ•°": f"{streak['years']}å¹´",
                            "æœŸé–“": f"{streak['start']}ã€œ{streak['end']}",
                            "ç¶™ç¶šä¸­": "âœ…" if streak.get("is_current") else ""
                        })
            if dept_records:
                dept_records.sort(key=lambda x: -int(x["é€£ç¶šå¹´æ•°"].replace("å¹´", "")))
                st.dataframe(pd.DataFrame(dept_records[:5]), use_container_width=True, hide_index=True)
            st.divider()

        if dept_data:
            for dept_name, year_data in dept_data.items():
                with st.expander(f"ğŸ“Œ {dept_name}", expanded=False):
                    if isinstance(year_data, dict):
                        for year in sorted(year_data.keys(), reverse=True):
                            st.markdown(f"**{year}å¹´**")
                            df = pd.DataFrame(year_data[year])
                            st.dataframe(df, use_container_width=True)

                        if len(year_data) > 1:
                            st.markdown("**ğŸ“ˆ 1ä½ã®æ¨ç§»**")
                            history = []
                            for year in sorted(year_data.keys(), reverse=True):
                                if year_data[year]:
                                    top = year_data[year][0]
                                    history.append({
                                        "å¹´åº¦": year,
                                        "1ä½": top.get("company", "-"),
                                        "å¾—ç‚¹": top.get("score", "-")
                                    })
                            if history:
                                st.dataframe(pd.DataFrame(history), use_container_width=True)
        else:
            st.info("éƒ¨é–€åˆ¥ãƒ‡ãƒ¼ã‚¿ã¯å­˜åœ¨ã—ãªã„ã‹å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    with tab7:
        st.header("ğŸ“ å‚è€ƒè³‡æ–™ï¼ˆä½¿ç”¨ã—ãŸURLï¼‰")

        if used_urls:
            # ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°URL
            st.subheader("ğŸ“Š ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            overall_urls = used_urls.get("overall", [])
            if overall_urls:
                url_df = pd.DataFrame([
                    {
                        "å¹´åº¦": item.get("year", ""),
                        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "âœ… æˆåŠŸ" if item.get("status") == "success" else "âŒ å¤±æ•—",
                        "URL": item.get("url", "")
                    }
                    for item in overall_urls
                ])
                # URLã‚’ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªãƒªãƒ³ã‚¯ã¨ã—ã¦è¡¨ç¤º
                st.dataframe(
                    url_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "URL": st.column_config.LinkColumn("URL", display_text="ğŸ”— ãƒªãƒ³ã‚¯ã‚’é–‹ã")
                    }
                )
            else:
                st.info("ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®URLãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            st.divider()

            # è©•ä¾¡é …ç›®åˆ¥URL
            st.subheader("ğŸ“‹ è©•ä¾¡é …ç›®åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            item_urls = used_urls.get("items", [])
            if item_urls:
                url_df = pd.DataFrame([
                    {
                        "é …ç›®å": item.get("name", ""),
                        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "âœ… æˆåŠŸ" if item.get("status") == "success" else "âŒ å¤±æ•—",
                        "URL": item.get("url", "")
                    }
                    for item in item_urls
                ])
                st.dataframe(
                    url_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "URL": st.column_config.LinkColumn("URL", display_text="ğŸ”— ãƒªãƒ³ã‚¯ã‚’é–‹ã")
                    }
                )
            else:
                st.info("è©•ä¾¡é …ç›®åˆ¥ã®URLãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            st.divider()

            # éƒ¨é–€åˆ¥URL
            st.subheader("ğŸ·ï¸ éƒ¨é–€åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            dept_urls = used_urls.get("departments", [])
            if dept_urls:
                url_df = pd.DataFrame([
                    {
                        "éƒ¨é–€å": item.get("name", ""),
                        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "âœ… æˆåŠŸ" if item.get("status") == "success" else "âŒ å¤±æ•—",
                        "URL": item.get("url", "")
                    }
                    for item in dept_urls
                ])
                st.dataframe(
                    url_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "URL": st.column_config.LinkColumn("URL", display_text="ğŸ”— ãƒªãƒ³ã‚¯ã‚’é–‹ã")
                    }
                )
            else:
                st.info("éƒ¨é–€åˆ¥ã®URLãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            if uploaded_years and not scraped_years:
                st.info("ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ãŸãŸã‚ã€å‚è€ƒURLã¯ã‚ã‚Šã¾ã›ã‚“")
            else:
                st.info("å‚è€ƒè³‡æ–™ï¼ˆURLæƒ…å ±ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“")

        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
        st.divider()
        st.markdown("**ğŸ“Œ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: [ã‚ªãƒªã‚³ãƒ³é¡§å®¢æº€è¶³åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°](https://life.oricon.co.jp/)")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.sidebar.divider()
st.sidebar.markdown("---")
st.sidebar.markdown("ğŸ“Œ **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: life.oricon.co.jp")
st.sidebar.markdown("ğŸ”§ **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 3.6")
